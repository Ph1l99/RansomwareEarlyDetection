{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7MRAbjbSimFh",
        "6oiIptz1jOcr",
        "VvAr_t5szsMR",
        "ciP9XIsf0CHB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules\n"
      ],
      "metadata": {
        "id": "0FCEEJGUeJ0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AugmMQ2VeEJ4",
        "outputId": "fc6c4fe3-69c1-433d-9763-fe337a5e644c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#ML auxiliary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "#SkLearn auxiliary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, top_k_accuracy_score\n",
        "\n",
        "#SkLearn classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.metrics import TopKCategoricalAccuracy"
      ],
      "metadata": {
        "id": "Cf9O57vUeZZ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS0r4IIkec_9",
        "outputId": "22609874-c4c4-4664-ff8c-c027c6c1ead6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 3.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets"
      ],
      "metadata": {
        "id": "n2qeWpIReikV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our dataset:\n",
        "- API calls: **48 API**\n",
        "- Families: 12 ransomware + 1 benign -> **5203 Samples**"
      ],
      "metadata": {
        "id": "ttjUnp9hhxbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_dataset = pd.read_csv('/content/drive/MyDrive/esrd_multiclass_dataset.csv')\n",
        "\n",
        "api_count = our_dataset.drop('Family', axis=1).sum()\n",
        "print(\"\\n\\nAPIs:\")\n",
        "print(api_count)\n",
        "\n",
        "data = our_dataset.to_numpy()\n",
        "x_ours = data[:, :-1].astype(float)\n",
        "y_ours = data[:, -1].astype(float)\n",
        "x_train_ours, x_test_ours, y_train_ours, y_test_ours = train_test_split(x_ours, y_ours, test_size=0.2)\n",
        "\n",
        "print(\"\\n\\nFamilies:\")\n",
        "family_count = our_dataset['Family']\n",
        "print(family_count.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PSDptHHefuy",
        "outputId": "23fa24de-c000-47c5-e078-313d7345b10c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "APIs:\n",
            "CreateProcessInternalW       964\n",
            "CreateServiceA                31\n",
            "CreateServiceW                98\n",
            "CryptExportKey               124\n",
            "CryptGenKey                  120\n",
            "DeviceIoControl               54\n",
            "EnumServicesStatusA           48\n",
            "EnumServicesStatusW           25\n",
            "FindWindowA                  118\n",
            "GetAdaptersAddresses         908\n",
            "GetComputerNameA             500\n",
            "GetComputerNameW            1987\n",
            "GetDiskFreeSpaceExW          684\n",
            "GetDiskFreeSpaceW            166\n",
            "GlobalMemoryStatusEx        1913\n",
            "InternetOpenA                133\n",
            "IsDebuggerPresent           2170\n",
            "LdrGetDllHandle               30\n",
            "LookupPrivilegeValueW       1505\n",
            "MoveFileWithProgressW        129\n",
            "NtAllocateVirtualMemory     3208\n",
            "NtCreateFile                  56\n",
            "NtCreateKey                  306\n",
            "NtGetContextThread           378\n",
            "NtMapViewOfSection            90\n",
            "NtProtectVirtualMemory      2684\n",
            "NtQuerySystemInformation      38\n",
            "NtResumeThread               372\n",
            "NtSetContextThread           345\n",
            "NtSetValueKey                334\n",
            "NtTerminateProcess           345\n",
            "NtUnmapViewOfSection         323\n",
            "NtWriteFile                  392\n",
            "Process32NextW               432\n",
            "RegOpenKeyExA                 35\n",
            "RegOpenKeyExW                 25\n",
            "RegSetValueExA               630\n",
            "RegSetValueExW               791\n",
            "SetFileAttributesW           933\n",
            "SetWindowsHookExA            365\n",
            "SetWindowsHookExW             47\n",
            "ShellExecuteExW             1671\n",
            "WriteConsoleA                 46\n",
            "WriteConsoleW                576\n",
            "WriteProcessMemory           303\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "Families:\n",
            "17    450\n",
            "14    450\n",
            "2     450\n",
            "5     450\n",
            "15    450\n",
            "23    450\n",
            "9     443\n",
            "0     432\n",
            "6     377\n",
            "3     359\n",
            "13    331\n",
            "8     295\n",
            "7     266\n",
            "Name: Family, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paranoia Dataset"
      ],
      "metadata": {
        "id": "7MRAbjbSimFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paranoia_dataset = pd.read_csv('/content/drive/MyDrive/paranoia_dataset.csv')\n",
        "data_para = paranoia_dataset.to_numpy()\n",
        "x_para = data_para[:, :-1].astype(float)\n",
        "y_para = data_para[:, -1].astype(float)"
      ],
      "metadata": {
        "id": "FP4Uxfajioka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our model with Paranoia Dataset\n",
        "\n",
        "* Accuracy = **93.24%**\n",
        "* Top-k Categorical Accuracy = **98.77%**\n",
        "* Recall = **91.00%**\n",
        "* Precision = **91.00%**\n",
        "* F1 Score = **91.00%**"
      ],
      "metadata": {
        "id": "6oiIptz1jOcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat_para = to_categorical(y_para)\n",
        "x_train_para, x_test_para, y_train_para, y_test_para = train_test_split(x_para, y_cat_para, test_size=0.2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=23, activation = \"relu\"))\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', TopKCategoricalAccuracy(k=2)])\n",
        "model.summary()\n",
        "model.fit(x_train_para, y_train_para, verbose=1, epochs=100, batch_size=15)\n",
        "\n",
        "predict_x_para=model.predict(x_test_para) \n",
        "y_pred_class_para=np.argmax(predict_x_para,axis=1)\n",
        "\n",
        "y_pred_para = model.predict(x_test_para)\n",
        "y_test_class_para = np.argmax(y_test_para, axis=1)\n",
        "print(confusion_matrix(y_test_class_para, y_pred_class_para))\n",
        "\n",
        "print(classification_report(y_test_class_para, y_pred_class_para))"
      ],
      "metadata": {
        "id": "CpP_b48HjONI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdd98ae-b015-4444-b10a-22f90e526935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               12288     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177,286\n",
            "Trainable params: 177,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "271/271 [==============================] - 2s 3ms/step - loss: 0.5795 - accuracy: 0.8191 - top_k_categorical_accuracy: 0.9087\n",
            "Epoch 2/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.3677 - accuracy: 0.8793 - top_k_categorical_accuracy: 0.9570\n",
            "Epoch 3/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9010 - top_k_categorical_accuracy: 0.9721\n",
            "Epoch 4/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9042 - top_k_categorical_accuracy: 0.9751\n",
            "Epoch 5/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.9089 - top_k_categorical_accuracy: 0.9790\n",
            "Epoch 6/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.2614 - accuracy: 0.9126 - top_k_categorical_accuracy: 0.9798\n",
            "Epoch 7/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2465 - accuracy: 0.9146 - top_k_categorical_accuracy: 0.9807\n",
            "Epoch 8/100\n",
            "271/271 [==============================] - 2s 7ms/step - loss: 0.2341 - accuracy: 0.9183 - top_k_categorical_accuracy: 0.9832\n",
            "Epoch 9/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2276 - accuracy: 0.9222 - top_k_categorical_accuracy: 0.9837\n",
            "Epoch 10/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9203 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 11/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2184 - accuracy: 0.9250 - top_k_categorical_accuracy: 0.9857\n",
            "Epoch 12/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2136 - accuracy: 0.9217 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 13/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9257 - top_k_categorical_accuracy: 0.9849\n",
            "Epoch 14/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2044 - accuracy: 0.9250 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 15/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2055 - accuracy: 0.9252 - top_k_categorical_accuracy: 0.9854\n",
            "Epoch 16/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.2023 - accuracy: 0.9267 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 17/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1993 - accuracy: 0.9282 - top_k_categorical_accuracy: 0.9857\n",
            "Epoch 18/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1952 - accuracy: 0.9296 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 19/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1978 - accuracy: 0.9287 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 20/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1920 - accuracy: 0.9294 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 21/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1985 - accuracy: 0.9287 - top_k_categorical_accuracy: 0.9857\n",
            "Epoch 22/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9287 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 23/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1916 - accuracy: 0.9314 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 24/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1945 - accuracy: 0.9309 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 25/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1878 - accuracy: 0.9311 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 26/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1887 - accuracy: 0.9304 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 27/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1938 - accuracy: 0.9267 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 28/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1850 - accuracy: 0.9314 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 29/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1843 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 30/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1899 - accuracy: 0.9306 - top_k_categorical_accuracy: 0.9869\n",
            "Epoch 31/100\n",
            "271/271 [==============================] - 2s 5ms/step - loss: 0.1873 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 32/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1868 - accuracy: 0.9329 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 33/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9259 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 34/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9311 - top_k_categorical_accuracy: 0.9869\n",
            "Epoch 35/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1821 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 36/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1818 - accuracy: 0.9331 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1798 - accuracy: 0.9341 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 38/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 39/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9326 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 40/100\n",
            "271/271 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9886\n",
            "Epoch 41/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9331 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 42/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9299 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 43/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1898 - accuracy: 0.9274 - top_k_categorical_accuracy: 0.9869\n",
            "Epoch 44/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9886\n",
            "Epoch 45/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9309 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 46/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1783 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 47/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 48/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.9346 - top_k_categorical_accuracy: 0.9889\n",
            "Epoch 49/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1802 - accuracy: 0.9341 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 50/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9333 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 51/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 52/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1930 - accuracy: 0.9287 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 53/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 54/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9331 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 55/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9338 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 56/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9341 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 57/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9353 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 58/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9306 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 59/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9348 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 60/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1866 - accuracy: 0.9329 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 61/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1899 - accuracy: 0.9304 - top_k_categorical_accuracy: 0.9862\n",
            "Epoch 62/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 63/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9891\n",
            "Epoch 64/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1745 - accuracy: 0.9343 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 65/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1755 - accuracy: 0.9333 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 66/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9333 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 67/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1767 - accuracy: 0.9356 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 68/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1901 - accuracy: 0.9306 - top_k_categorical_accuracy: 0.9862\n",
            "Epoch 69/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1918 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 70/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 71/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9311 - top_k_categorical_accuracy: 0.9859\n",
            "Epoch 72/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9338 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 73/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9316 - top_k_categorical_accuracy: 0.9869\n",
            "Epoch 74/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.9358 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 75/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9361 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 76/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9348 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 77/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 78/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9346 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 79/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9333 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 80/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9338 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 81/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9333 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 82/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9314 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 83/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1892 - accuracy: 0.9301 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 84/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1767 - accuracy: 0.9351 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 85/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9353 - top_k_categorical_accuracy: 0.9889\n",
            "Epoch 86/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9366 - top_k_categorical_accuracy: 0.9874\n",
            "Epoch 87/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9343 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 88/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9346 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 89/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9329 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 90/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1759 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 91/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1717 - accuracy: 0.9314 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 92/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9351 - top_k_categorical_accuracy: 0.9877\n",
            "Epoch 93/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9348 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 94/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9324 - top_k_categorical_accuracy: 0.9867\n",
            "Epoch 95/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9299 - top_k_categorical_accuracy: 0.9884\n",
            "Epoch 96/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1794 - accuracy: 0.9336 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 97/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9351 - top_k_categorical_accuracy: 0.9879\n",
            "Epoch 98/100\n",
            "271/271 [==============================] - 2s 6ms/step - loss: 0.1785 - accuracy: 0.9306 - top_k_categorical_accuracy: 0.9872\n",
            "Epoch 99/100\n",
            "271/271 [==============================] - 1s 5ms/step - loss: 0.1747 - accuracy: 0.9331 - top_k_categorical_accuracy: 0.9882\n",
            "Epoch 100/100\n",
            "271/271 [==============================] - 1s 3ms/step - loss: 0.1717 - accuracy: 0.9351 - top_k_categorical_accuracy: 0.9886\n",
            "[[182   0   0  12   8   0]\n",
            " [  0 154   0   1   0   3]\n",
            " [  1   0 175   0   3   1]\n",
            " [  4   2   0 171   2   1]\n",
            " [  6   5  17  16 151   0]\n",
            " [  0   0   0  12   5  81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.90      0.92       202\n",
            "           1       0.96      0.97      0.97       158\n",
            "           2       0.91      0.97      0.94       180\n",
            "           3       0.81      0.95      0.87       180\n",
            "           4       0.89      0.77      0.83       195\n",
            "           5       0.94      0.83      0.88        98\n",
            "\n",
            "    accuracy                           0.90      1013\n",
            "   macro avg       0.91      0.90      0.90      1013\n",
            "weighted avg       0.91      0.90      0.90      1013\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our model with our dataset\n",
        "\n",
        "* Accuracy = **82.29%**\n",
        "* Top-k Categorical Accuracy = **90.51%**\n",
        "* Recall = **80.00%**\n",
        "* Precision = **78.00%**\n",
        "* F1 Score = **78.00%**"
      ],
      "metadata": {
        "id": "ynqVkLJUp7A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat_ours = to_categorical(y_ours)\n",
        "x_train_ours, x_test_ours, y_train_ours, y_test_ours = train_test_split(x_ours, y_cat_ours, test_size=0.2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=45, activation = \"relu\"))\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(24, activation = \"softmax\"))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', TopKCategoricalAccuracy(k=2)])\n",
        "model.summary()\n",
        "model.fit(x_train_ours, y_train_ours, verbose=1, epochs=100, batch_size=10)\n",
        "\n",
        "predict_x=model.predict(x_test_ours) \n",
        "y_pred_class=np.argmax(predict_x,axis=1)\n",
        "\n",
        "y_pred = model.predict(x_test_ours)\n",
        "y_test_class = np.argmax(y_test_ours, axis=1)\n",
        "print(confusion_matrix(y_test_class, y_pred_class))\n",
        "\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "\n",
        "print('precision: ' + str(precision_score(y_pred_class, y_test_class, average='weighted')))\n",
        "print('recall: ' + str(recall_score(y_pred_class, y_test_class, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(y_pred_class, y_test_class, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(y_pred_class, y_test_class)))"
      ],
      "metadata": {
        "id": "hJk56InyqAqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7fe9623-740d-40ae-e2d8-be467f41401f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 512)               23552     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 24)                3096      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 190,872\n",
            "Trainable params: 190,872\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.2827 - accuracy: 0.6194 - top_k_categorical_accuracy: 0.7319\n",
            "Epoch 2/100\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.8487 - accuracy: 0.7285 - top_k_categorical_accuracy: 0.8236\n",
            "Epoch 3/100\n",
            "417/417 [==============================] - 3s 7ms/step - loss: 0.7580 - accuracy: 0.7576 - top_k_categorical_accuracy: 0.8429\n",
            "Epoch 4/100\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.7068 - accuracy: 0.7679 - top_k_categorical_accuracy: 0.8546\n",
            "Epoch 5/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6716 - accuracy: 0.7734 - top_k_categorical_accuracy: 0.8698\n",
            "Epoch 6/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6383 - accuracy: 0.7809 - top_k_categorical_accuracy: 0.8693\n",
            "Epoch 7/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6245 - accuracy: 0.7953 - top_k_categorical_accuracy: 0.8779\n",
            "Epoch 8/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6068 - accuracy: 0.7963 - top_k_categorical_accuracy: 0.8847\n",
            "Epoch 9/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5941 - accuracy: 0.8015 - top_k_categorical_accuracy: 0.8856\n",
            "Epoch 10/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5858 - accuracy: 0.8003 - top_k_categorical_accuracy: 0.8902\n",
            "Epoch 11/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.8078 - top_k_categorical_accuracy: 0.8938\n",
            "Epoch 12/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.8054 - top_k_categorical_accuracy: 0.8940\n",
            "Epoch 13/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5571 - accuracy: 0.8126 - top_k_categorical_accuracy: 0.8967\n",
            "Epoch 14/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5569 - accuracy: 0.8085 - top_k_categorical_accuracy: 0.8931\n",
            "Epoch 15/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5479 - accuracy: 0.8107 - top_k_categorical_accuracy: 0.8981\n",
            "Epoch 16/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5408 - accuracy: 0.8116 - top_k_categorical_accuracy: 0.8964\n",
            "Epoch 17/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5358 - accuracy: 0.8160 - top_k_categorical_accuracy: 0.9000\n",
            "Epoch 18/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5308 - accuracy: 0.8150 - top_k_categorical_accuracy: 0.9027\n",
            "Epoch 19/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5296 - accuracy: 0.8092 - top_k_categorical_accuracy: 0.8988\n",
            "Epoch 20/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5311 - accuracy: 0.8145 - top_k_categorical_accuracy: 0.8986\n",
            "Epoch 21/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5240 - accuracy: 0.8123 - top_k_categorical_accuracy: 0.8972\n",
            "Epoch 22/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5195 - accuracy: 0.8174 - top_k_categorical_accuracy: 0.9005\n",
            "Epoch 23/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5131 - accuracy: 0.8169 - top_k_categorical_accuracy: 0.9027\n",
            "Epoch 24/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5201 - accuracy: 0.8181 - top_k_categorical_accuracy: 0.8996\n",
            "Epoch 25/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5137 - accuracy: 0.8162 - top_k_categorical_accuracy: 0.9027\n",
            "Epoch 26/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5118 - accuracy: 0.8172 - top_k_categorical_accuracy: 0.9068\n",
            "Epoch 27/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5074 - accuracy: 0.8172 - top_k_categorical_accuracy: 0.9022\n",
            "Epoch 28/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5048 - accuracy: 0.8167 - top_k_categorical_accuracy: 0.9039\n",
            "Epoch 29/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5051 - accuracy: 0.8193 - top_k_categorical_accuracy: 0.8996\n",
            "Epoch 30/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5167 - accuracy: 0.8174 - top_k_categorical_accuracy: 0.9010\n",
            "Epoch 31/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5046 - accuracy: 0.8198 - top_k_categorical_accuracy: 0.9041\n",
            "Epoch 32/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4986 - accuracy: 0.8184 - top_k_categorical_accuracy: 0.9037\n",
            "Epoch 33/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4992 - accuracy: 0.8212 - top_k_categorical_accuracy: 0.9022\n",
            "Epoch 34/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4974 - accuracy: 0.8215 - top_k_categorical_accuracy: 0.9053\n",
            "Epoch 35/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5084 - accuracy: 0.8198 - top_k_categorical_accuracy: 0.9034\n",
            "Epoch 36/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4990 - accuracy: 0.8188 - top_k_categorical_accuracy: 0.9053\n",
            "Epoch 37/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4892 - accuracy: 0.8212 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 38/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4974 - accuracy: 0.8196 - top_k_categorical_accuracy: 0.9082\n",
            "Epoch 39/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4961 - accuracy: 0.8224 - top_k_categorical_accuracy: 0.9056\n",
            "Epoch 40/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4874 - accuracy: 0.8212 - top_k_categorical_accuracy: 0.9041\n",
            "Epoch 41/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4935 - accuracy: 0.8234 - top_k_categorical_accuracy: 0.9065\n",
            "Epoch 42/100\n",
            "417/417 [==============================] - 3s 7ms/step - loss: 0.4874 - accuracy: 0.8184 - top_k_categorical_accuracy: 0.9070\n",
            "Epoch 43/100\n",
            "417/417 [==============================] - 2s 6ms/step - loss: 0.4909 - accuracy: 0.8232 - top_k_categorical_accuracy: 0.9056\n",
            "Epoch 44/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4926 - accuracy: 0.8203 - top_k_categorical_accuracy: 0.9051\n",
            "Epoch 45/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4891 - accuracy: 0.8205 - top_k_categorical_accuracy: 0.9056\n",
            "Epoch 46/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4935 - accuracy: 0.8212 - top_k_categorical_accuracy: 0.9041\n",
            "Epoch 47/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4988 - accuracy: 0.8200 - top_k_categorical_accuracy: 0.9032\n",
            "Epoch 48/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4860 - accuracy: 0.8217 - top_k_categorical_accuracy: 0.9085\n",
            "Epoch 49/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4904 - accuracy: 0.8205 - top_k_categorical_accuracy: 0.9049\n",
            "Epoch 50/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4800 - accuracy: 0.8251 - top_k_categorical_accuracy: 0.9068\n",
            "Epoch 51/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4915 - accuracy: 0.8208 - top_k_categorical_accuracy: 0.9080\n",
            "Epoch 52/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4832 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9061\n",
            "Epoch 53/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4823 - accuracy: 0.8244 - top_k_categorical_accuracy: 0.9077\n",
            "Epoch 54/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.8244 - top_k_categorical_accuracy: 0.9097\n",
            "Epoch 55/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4850 - accuracy: 0.8234 - top_k_categorical_accuracy: 0.9063\n",
            "Epoch 56/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4867 - accuracy: 0.8227 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 57/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4862 - accuracy: 0.8212 - top_k_categorical_accuracy: 0.9044\n",
            "Epoch 58/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4883 - accuracy: 0.8224 - top_k_categorical_accuracy: 0.9073\n",
            "Epoch 59/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4841 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9046\n",
            "Epoch 60/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4837 - accuracy: 0.8251 - top_k_categorical_accuracy: 0.9077\n",
            "Epoch 61/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4993 - accuracy: 0.8220 - top_k_categorical_accuracy: 0.9063\n",
            "Epoch 62/100\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.4941 - accuracy: 0.8188 - top_k_categorical_accuracy: 0.9077\n",
            "Epoch 63/100\n",
            "417/417 [==============================] - 3s 7ms/step - loss: 0.4806 - accuracy: 0.8232 - top_k_categorical_accuracy: 0.9068\n",
            "Epoch 64/100\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.4795 - accuracy: 0.8229 - top_k_categorical_accuracy: 0.9063\n",
            "Epoch 65/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4802 - accuracy: 0.8263 - top_k_categorical_accuracy: 0.9092\n",
            "Epoch 66/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4873 - accuracy: 0.8198 - top_k_categorical_accuracy: 0.9056\n",
            "Epoch 67/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4844 - accuracy: 0.8227 - top_k_categorical_accuracy: 0.9082\n",
            "Epoch 68/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4808 - accuracy: 0.8270 - top_k_categorical_accuracy: 0.9082\n",
            "Epoch 69/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4796 - accuracy: 0.8217 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 70/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4770 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9077\n",
            "Epoch 71/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4781 - accuracy: 0.8260 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 72/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4903 - accuracy: 0.8246 - top_k_categorical_accuracy: 0.9068\n",
            "Epoch 73/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4806 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9085\n",
            "Epoch 74/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4769 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9099\n",
            "Epoch 75/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4758 - accuracy: 0.8253 - top_k_categorical_accuracy: 0.9037\n",
            "Epoch 76/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4803 - accuracy: 0.8217 - top_k_categorical_accuracy: 0.9094\n",
            "Epoch 77/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4797 - accuracy: 0.8198 - top_k_categorical_accuracy: 0.9063\n",
            "Epoch 78/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4791 - accuracy: 0.8205 - top_k_categorical_accuracy: 0.9099\n",
            "Epoch 79/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4818 - accuracy: 0.8260 - top_k_categorical_accuracy: 0.9049\n",
            "Epoch 80/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4731 - accuracy: 0.8244 - top_k_categorical_accuracy: 0.9092\n",
            "Epoch 81/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4749 - accuracy: 0.8251 - top_k_categorical_accuracy: 0.9077\n",
            "Epoch 82/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4725 - accuracy: 0.8253 - top_k_categorical_accuracy: 0.9101\n",
            "Epoch 83/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4815 - accuracy: 0.8224 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 84/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4897 - accuracy: 0.8217 - top_k_categorical_accuracy: 0.9053\n",
            "Epoch 85/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4777 - accuracy: 0.8258 - top_k_categorical_accuracy: 0.9065\n",
            "Epoch 86/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4731 - accuracy: 0.8284 - top_k_categorical_accuracy: 0.9085\n",
            "Epoch 87/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4794 - accuracy: 0.8239 - top_k_categorical_accuracy: 0.9099\n",
            "Epoch 88/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4749 - accuracy: 0.8232 - top_k_categorical_accuracy: 0.9094\n",
            "Epoch 89/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4773 - accuracy: 0.8256 - top_k_categorical_accuracy: 0.9061\n",
            "Epoch 90/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4753 - accuracy: 0.8265 - top_k_categorical_accuracy: 0.9085\n",
            "Epoch 91/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4811 - accuracy: 0.8236 - top_k_categorical_accuracy: 0.9061\n",
            "Epoch 92/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4803 - accuracy: 0.8203 - top_k_categorical_accuracy: 0.9063\n",
            "Epoch 93/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8208 - top_k_categorical_accuracy: 0.9073\n",
            "Epoch 94/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4827 - accuracy: 0.8227 - top_k_categorical_accuracy: 0.9094\n",
            "Epoch 95/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4908 - accuracy: 0.8215 - top_k_categorical_accuracy: 0.9051\n",
            "Epoch 96/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4826 - accuracy: 0.8222 - top_k_categorical_accuracy: 0.9058\n",
            "Epoch 97/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4763 - accuracy: 0.8241 - top_k_categorical_accuracy: 0.9075\n",
            "Epoch 98/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4715 - accuracy: 0.8253 - top_k_categorical_accuracy: 0.9106\n",
            "Epoch 99/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4728 - accuracy: 0.8246 - top_k_categorical_accuracy: 0.9065\n",
            "Epoch 100/100\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.4718 - accuracy: 0.8234 - top_k_categorical_accuracy: 0.9058\n",
            "[[66  5  5  0 12  2  1  7  4  1  0  0  0]\n",
            " [ 1 81  0  2  0  1  0  6  0  0  2  0  0]\n",
            " [ 0  7 42  0  6  0  0  1  1  0  2  2  0]\n",
            " [ 0  1  0 70  1  0  0  2  1  0  0  6  0]\n",
            " [ 1  5  1  3 46  0  0  1  0  0  0  5  0]\n",
            " [ 1  6  0  2  4 23  0 14  1  0  0  2  0]\n",
            " [ 0  0  0  2  7  1 38  0  1  0  0  0  0]\n",
            " [ 4  3  0  0  2  9  2 62  1  0  0  2  0]\n",
            " [ 1  8  4  1 24  5  0  2 36  1  0  0  0]\n",
            " [ 0  3  0  0  0  0  0  0  0 92  0  0  0]\n",
            " [ 1  6  0  1  4  0  0  0  1  0 82  0  0]\n",
            " [ 0  1  0  6  7  3  0 15  1  0  0 56  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 93]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.74       103\n",
            "           2       0.64      0.87      0.74        93\n",
            "           3       0.81      0.69      0.74        61\n",
            "           5       0.80      0.86      0.83        81\n",
            "           6       0.41      0.74      0.53        62\n",
            "           7       0.52      0.43      0.47        53\n",
            "           8       0.93      0.78      0.84        49\n",
            "           9       0.56      0.73      0.64        85\n",
            "          13       0.77      0.44      0.56        82\n",
            "          14       0.98      0.97      0.97        95\n",
            "          15       0.95      0.86      0.91        95\n",
            "          17       0.77      0.63      0.69        89\n",
            "          23       1.00      1.00      1.00        93\n",
            "\n",
            "    accuracy                           0.76      1041\n",
            "   macro avg       0.77      0.74      0.74      1041\n",
            "weighted avg       0.79      0.76      0.76      1041\n",
            "\n",
            "precision: 0.7767366014175632\n",
            "recall: 0.7560038424591738\n",
            "f1-score: 0.7530821627894456\n",
            "accuracy: 0.7560038424591738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paranoia Model with Paranoia Dataset\n",
        "\n",
        "* Accuracy = **89.04%**\n",
        "* Top-k Categorical Accuracy = **-**\n",
        "* Recall = **89.04%**\n",
        "* Precision = **92.82%**\n",
        "* F1 Score = **90.84%**"
      ],
      "metadata": {
        "id": "VvAr_t5szsMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_para, x_test_para, y_train_para, y_test_para = train_test_split(x_para, y_para, test_size=0.2)\n",
        "\n",
        "randclf = RandomForestClassifier(n_estimators=50, random_state=10)\n",
        "randclf.fit(x_train_para, y_train_para)\n",
        "y_train_pred_para = randclf.predict(x_train_para)\n",
        "print('train precision: ' + str(precision_score(y_train_para, y_train_pred_para, average='weighted')))\n",
        "print('train recall: ' + str(recall_score(y_train_para, y_train_pred_para, average='weighted')))\n",
        "print('train f1-score: ' + str(f1_score(y_train_para, y_train_pred_para, average='weighted')))\n",
        "# print('train top_k_accuracy_score: ' + str(top_k_accuracy_score(y_train, y_train_pred, k=2)))\n",
        "print('train accuracy: ' + str(accuracy_score(y_train_para, y_train_pred_para)))\n",
        "\n",
        "y_test_pred_para = randclf.predict(x_test_para)\n",
        "print('test precision: ' + str(precision_score(y_test_para, y_test_pred_para, average='weighted')))\n",
        "print('test recall: ' + str(recall_score(y_test_para, y_test_pred_para, average='weighted')))\n",
        "print('test f1-score: ' + str(f1_score(y_test_para, y_test_pred_para, average='weighted')))\n",
        "print('test top_k_accuracy_score: ' + str(top_k_accuracy_score(y_test_para, randclf.predict_proba(x_test_para), k=2)))\n",
        "print('test accuracy: ' + str(accuracy_score(y_test_para, y_test_pred_para)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qSBZLjizwIw",
        "outputId": "17339ede-2217-4954-a8a3-62d2458ebd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train precision: 0.9347182094400233\n",
            "train recall: 0.9333497901752653\n",
            "train f1-score: 0.9330554016938052\n",
            "train accuracy: 0.9333497901752653\n",
            "test precision: 0.9217313229125541\n",
            "test recall: 0.9200394866732478\n",
            "test f1-score: 0.9194539470766399\n",
            "test top_k_accuracy_score: 0.9753208292201382\n",
            "test accuracy: 0.9200394866732478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paranoia Model with Our Dataset\n",
        "\n",
        "* Accuracy = **71.37%**\n",
        "* Top-k Categorical Accuracy = **-**\n",
        "* Recall = **71.37%**\n",
        "* Precision = **90.19%**\n",
        "* F1 Score = **78.88%**"
      ],
      "metadata": {
        "id": "ciP9XIsf0CHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randclf = RandomForestClassifier(n_estimators=50, random_state=10)\n",
        "randclf.fit(x_train_ours, y_train_ours)\n",
        "y_train_pred_ours = randclf.predict(x_train_ours)\n",
        "print('train precision: ' + str(precision_score(y_train_ours, y_train_pred_ours, average='weighted')))\n",
        "print('train recall: ' + str(recall_score(y_train_ours, y_train_pred_ours, average='weighted')))\n",
        "print('train f1-score: ' + str(f1_score(y_train_ours, y_train_pred_ours, average='weighted')))\n",
        "print('train accuracy: ' + str(accuracy_score(y_train_ours, y_train_pred_ours)))\n",
        "\n",
        "y_test_pred_ours = randclf.predict(x_test_ours)\n",
        "print('test precision: ' + str(precision_score(y_test_ours, y_test_pred_ours, average='weighted')))\n",
        "print('test recall: ' + str(recall_score(y_test_ours, y_test_pred_ours, average='weighted')))\n",
        "print('test f1-score: ' + str(f1_score(y_test_ours, y_test_pred_ours, average='weighted')))\n",
        "print('test accuracy: ' + str(accuracy_score(y_test_ours, y_test_pred_ours)))\n",
        "print('test top_k_accuracy_score: ' + str(top_k_accuracy_score(y_test_ours, randclf.predict_proba(x_test_ours), k=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNHApiC50Ffp",
        "outputId": "2f5366c6-b33d-4e28-9edd-a3c80876a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train precision: 0.8378736449973225\n",
            "train recall: 0.826045170591062\n",
            "train f1-score: 0.8279886509422316\n",
            "train accuracy: 0.826045170591062\n",
            "test precision: 0.7929147294167281\n",
            "test recall: 0.7877041306436119\n",
            "test f1-score: 0.7878844031096703\n",
            "test accuracy: 0.7877041306436119\n",
            "test top_k_accuracy_score: 0.8674351585014409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other models"
      ],
      "metadata": {
        "id": "Z3u2XCT5YJmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bernoulli Naive Bayes"
      ],
      "metadata": {
        "id": "UYcj8-W263BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bern_na_bay = BernoulliNB()\n",
        "\n",
        "scores = cross_val_score(bern_na_bay, x_ours, y_ours, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_ours, y_ours, test_size=0.2, random_state=75)\n",
        "bern_na_bay.fit(x_train, y_train)\n",
        "\n",
        "predict=bern_na_bay.predict(x_test)\n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))\n",
        "print('top-k accuracy: ' + str(top_k_accuracy_score(y_test, bern_na_bay.predict_proba(x_test), k=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR6pi0zSWP5N",
        "outputId": "24abb963-d577-4dab-b2a4-cb7df5b5392c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5494873025247304\n",
            "precision: 0.6141311317508318\n",
            "recall: 0.56388088376561\n",
            "f1-score: 0.5594160220262696\n",
            "accuracy: 0.56388088376561\n",
            "top-k accuracy: 0.6733909702209414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "fHxD6av3YMFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_for_classifier=RandomForestClassifier()\n",
        "\n",
        "scores = cross_val_score(rand_for_classifier, x_ours, y_ours, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_ours, y_ours, test_size=0.2, random_state=75)\n",
        "rand_for_classifier.fit(x_train, y_train)\n",
        "\n",
        "predict=rand_for_classifier.predict(x_test) \n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))\n",
        "print('top-k accuracy: ' + str(top_k_accuracy_score(y_test, rand_for_classifier.predict_proba(x_test), k=2)))"
      ],
      "metadata": {
        "id": "iByfYD26ZYJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6763e5f0-5146-437b-f163-8649b06ae010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7757031596043114\n",
            "precision: 0.811429459769444\n",
            "recall: 0.7886647454370798\n",
            "f1-score: 0.7865383884128152\n",
            "accuracy: 0.7886647454370798\n",
            "top-k accuracy: 0.8607108549471661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "nejjuDQxYNiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "scores = cross_val_score(knn, x_ours, y_ours, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_ours, y_ours, test_size=0.2, random_state=75)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "predict=knn.predict(x_test) \n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))\n",
        "print('top-k accuracy: ' + str(top_k_accuracy_score(y_test, knn.predict_proba(x_test), k=2)))"
      ],
      "metadata": {
        "id": "uqkMLRZQYZ1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd521dab-bab2-41d9-b0ce-86951d9808e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65231322899749\n",
            "precision: 0.7725907999734125\n",
            "recall: 0.7521613832853026\n",
            "f1-score: 0.7534116062348658\n",
            "accuracy: 0.7521613832853026\n",
            "top-k accuracy: 0.8203650336215178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary classification"
      ],
      "metadata": {
        "id": "05C5Hk7kmIMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preparation\n",
        "First of all we transform the dataset to a two-class one by replacing all families identifiers with *Ransomware* or *Benign* classes."
      ],
      "metadata": {
        "id": "ep9u44_PsWl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_binary_dataset = pd.read_csv('/content/drive/MyDrive/esrd_binary_dataset.csv')\n",
        "\n",
        "data = our_binary_dataset.to_numpy()\n",
        "x_ours = data[:, :-1].astype(float)\n",
        "y_ours = data[:, -1].astype(float)\n",
        "\n",
        "print(\"\\n\\nFamilies:\")\n",
        "family_count = our_binary_dataset['Family']\n",
        "print(family_count.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRZAW5pkkv3u",
        "outputId": "a804fb42-3c08-4af6-95ec-8eb65c988028"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Families:\n",
            "1    1200\n",
            "0    1111\n",
            "Name: Family, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "our_binary_dataset['Family'] = np.where(our_binary_dataset.Family <= 22, 1, 0)"
      ],
      "metadata": {
        "id": "kjvEvU-Lkkgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_binary_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Su1T5WAoOg3",
        "outputId": "0ae57537-1177-4780-fa66-d7e652dd2cba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2311, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then split the labels from the features in order to run the classification tasks."
      ],
      "metadata": {
        "id": "bOCtoySruCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = our_binary_dataset.to_numpy()\n",
        "x = data[:, :-1].astype(int)\n",
        "y = data[:, -1].astype(int)"
      ],
      "metadata": {
        "id": "NrcDBsS_ocp8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Models\n",
        "In this section we train and validate the three models which have been already mentioned above for what concerns binary classification"
      ],
      "metadata": {
        "id": "V96qNns2scXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bernoulli Naive Bayes"
      ],
      "metadata": {
        "id": "txvyYDALsemX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bern_na_bay = BernoulliNB()\n",
        "\n",
        "scores = cross_val_score(bern_na_bay, x, y, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=75)\n",
        "bern_na_bay.fit(x_train, y_train)\n",
        "\n",
        "predict=bern_na_bay.predict(x_test) \n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))"
      ],
      "metadata": {
        "id": "dng-Le5Qoyby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19802a41-8176-4112-b6cd-74adc51d27e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9826877145842662\n",
            "precision: 0.9754957785195366\n",
            "recall: 0.9740820734341252\n",
            "f1-score: 0.9741331446777807\n",
            "accuracy: 0.9740820734341252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "DFBAh0pMsg4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "scores = cross_val_score(knn, x, y, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=75)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "predict=knn.predict(x_test) \n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8ZxnGh9p0PO",
        "outputId": "d8396518-3331-4da4-ffaf-98fa8f2bde38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9995670995670995\n",
            "precision: 1.0\n",
            "recall: 1.0\n",
            "f1-score: 1.0\n",
            "accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "MWWmhB3jsj34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_for_classifier=RandomForestClassifier()\n",
        "\n",
        "scores = cross_val_score(rand_for_classifier, x, y, cv=10)\n",
        "print(scores.mean())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=75)\n",
        "rand_for_classifier.fit(x_train, y_train)\n",
        "\n",
        "predict=rand_for_classifier.predict(x_test) \n",
        "\n",
        "print('precision: ' + str(precision_score(predict, y_test, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict, y_test, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict, y_test, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0efW3nlwYxk",
        "outputId": "df6e12f6-142b-44a2-f51a-aeab8a654b53"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9952380952380953\n",
            "precision: 1.0\n",
            "recall: 1.0\n",
            "f1-score: 1.0\n",
            "accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ],
      "metadata": {
        "id": "cc9_47jk98ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ours, x_test_ours, y_train_ours, y_test_ours = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=48, activation = \"relu\"))\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = \"softmax\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x_train_ours, y_train_ours, verbose=1, epochs=100, batch_size=10)\n",
        "\n",
        "predict_x=model.predict(x_test_ours)\n",
        "\n",
        "print('precision: ' + str(precision_score(predict_x, y_test_ours, average='weighted')))\n",
        "print('recall: ' + str(recall_score(predict_x, y_test_ours, average='weighted')))\n",
        "print('f1-score: ' + str(f1_score(predict_x, y_test_ours, average='weighted')))\n",
        "print('accuracy: ' + str(accuracy_score(predict_x, y_test_ours)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHD2a2_gHYoP",
        "outputId": "b1f621da-0420-493e-8d2b-0d1f99fd4fab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 512)               25088     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 189,441\n",
            "Trainable params: 189,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.5195\n",
            "Epoch 2/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.5195\n",
            "Epoch 3/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.9114e-04 - accuracy: 0.5195\n",
            "Epoch 4/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.5150e-05 - accuracy: 0.5195\n",
            "Epoch 5/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.8410e-05 - accuracy: 0.5195\n",
            "Epoch 6/100\n",
            "185/185 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.5195\n",
            "Epoch 7/100\n",
            "185/185 [==============================] - 1s 8ms/step - loss: 0.0039 - accuracy: 0.5195\n",
            "Epoch 8/100\n",
            "185/185 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.5195\n",
            "Epoch 9/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.5195\n",
            "Epoch 10/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.0675e-05 - accuracy: 0.5195\n",
            "Epoch 11/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.3379e-05 - accuracy: 0.5195\n",
            "Epoch 12/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.1625e-05 - accuracy: 0.5195\n",
            "Epoch 13/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.1730e-05 - accuracy: 0.5195\n",
            "Epoch 14/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.5639e-06 - accuracy: 0.5195\n",
            "Epoch 15/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.0141e-05 - accuracy: 0.5195\n",
            "Epoch 16/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.0834e-05 - accuracy: 0.5195\n",
            "Epoch 17/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.7735e-06 - accuracy: 0.5195\n",
            "Epoch 18/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.8558e-06 - accuracy: 0.5195\n",
            "Epoch 19/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.2281e-06 - accuracy: 0.5195\n",
            "Epoch 20/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.8210e-06 - accuracy: 0.5195\n",
            "Epoch 21/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.5753e-06 - accuracy: 0.5195\n",
            "Epoch 22/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.0244e-06 - accuracy: 0.5195\n",
            "Epoch 23/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.2717e-06 - accuracy: 0.5195\n",
            "Epoch 24/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.6432e-06 - accuracy: 0.5195\n",
            "Epoch 25/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.1220e-06 - accuracy: 0.5195\n",
            "Epoch 26/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 1.7255e-06 - accuracy: 0.5195\n",
            "Epoch 27/100\n",
            "185/185 [==============================] - 1s 8ms/step - loss: 6.1731e-07 - accuracy: 0.5195\n",
            "Epoch 28/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.2881e-07 - accuracy: 0.5195\n",
            "Epoch 29/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.1003e-07 - accuracy: 0.5195\n",
            "Epoch 30/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.0912e-07 - accuracy: 0.5195\n",
            "Epoch 31/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.1264e-07 - accuracy: 0.5195\n",
            "Epoch 32/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.8700e-07 - accuracy: 0.5195\n",
            "Epoch 33/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.7484e-07 - accuracy: 0.5195\n",
            "Epoch 34/100\n",
            "185/185 [==============================] - 1s 7ms/step - loss: 3.2702e-07 - accuracy: 0.5195\n",
            "Epoch 35/100\n",
            "185/185 [==============================] - 1s 7ms/step - loss: 1.4072e-07 - accuracy: 0.5195\n",
            "Epoch 36/100\n",
            "185/185 [==============================] - 1s 7ms/step - loss: 4.6619e-07 - accuracy: 0.5195\n",
            "Epoch 37/100\n",
            "185/185 [==============================] - 1s 6ms/step - loss: 2.7336e-07 - accuracy: 0.5195\n",
            "Epoch 38/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.3837e-07 - accuracy: 0.5195\n",
            "Epoch 39/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.8521e-07 - accuracy: 0.5195\n",
            "Epoch 40/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.9653e-08 - accuracy: 0.5195\n",
            "Epoch 41/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.8173e-07 - accuracy: 0.5195\n",
            "Epoch 42/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 9.3071e-08 - accuracy: 0.5195\n",
            "Epoch 43/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.7816e-08 - accuracy: 0.5195\n",
            "Epoch 44/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.7164e-08 - accuracy: 0.5195\n",
            "Epoch 45/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.7432e-08 - accuracy: 0.5195\n",
            "Epoch 46/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 3.3592e-08 - accuracy: 0.5195\n",
            "Epoch 47/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.7115e-08 - accuracy: 0.5195\n",
            "Epoch 48/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.5413e-08 - accuracy: 0.5195\n",
            "Epoch 49/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.6383e-08 - accuracy: 0.5195\n",
            "Epoch 50/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.9582e-08 - accuracy: 0.5195\n",
            "Epoch 51/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.6242e-08 - accuracy: 0.5195\n",
            "Epoch 52/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.1582e-08 - accuracy: 0.5195\n",
            "Epoch 53/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 5.7895e-08 - accuracy: 0.5195\n",
            "Epoch 54/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 1.9820e-08 - accuracy: 0.5195\n",
            "Epoch 55/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.7428e-08 - accuracy: 0.5195\n",
            "Epoch 56/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.8453e-08 - accuracy: 0.5195\n",
            "Epoch 57/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.8112e-08 - accuracy: 0.5195\n",
            "Epoch 58/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.6423e-08 - accuracy: 0.5195\n",
            "Epoch 59/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.8557e-08 - accuracy: 0.5195\n",
            "Epoch 60/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 3.1221e-08 - accuracy: 0.5195\n",
            "Epoch 61/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.2835e-08 - accuracy: 0.5195\n",
            "Epoch 62/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 8.4573e-08 - accuracy: 0.5195\n",
            "Epoch 63/100\n",
            "185/185 [==============================] - 1s 6ms/step - loss: 1.8602e-08 - accuracy: 0.5195\n",
            "Epoch 64/100\n",
            "185/185 [==============================] - 2s 8ms/step - loss: 8.7770e-09 - accuracy: 0.5195\n",
            "Epoch 65/100\n",
            "185/185 [==============================] - 1s 7ms/step - loss: 1.0266e-08 - accuracy: 0.5195\n",
            "Epoch 66/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.1058e-08 - accuracy: 0.5195\n",
            "Epoch 67/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.9884e-08 - accuracy: 0.5195\n",
            "Epoch 68/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.2880e-08 - accuracy: 0.5195\n",
            "Epoch 69/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 9.2702e-09 - accuracy: 0.5195\n",
            "Epoch 70/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 9.5117e-09 - accuracy: 0.5195\n",
            "Epoch 71/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.3599e-09 - accuracy: 0.5195\n",
            "Epoch 72/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 3.9389e-09 - accuracy: 0.5195\n",
            "Epoch 73/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 8.7054e-09 - accuracy: 0.5195\n",
            "Epoch 74/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.1045e-09 - accuracy: 0.5195\n",
            "Epoch 75/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 2.0472e-08 - accuracy: 0.5195\n",
            "Epoch 76/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.4417e-08 - accuracy: 0.5195\n",
            "Epoch 77/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.8749e-09 - accuracy: 0.5195\n",
            "Epoch 78/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.9062e-10 - accuracy: 0.5195\n",
            "Epoch 79/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.5990e-08 - accuracy: 0.5195\n",
            "Epoch 80/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.7910e-09 - accuracy: 0.5195\n",
            "Epoch 81/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.5607e-08 - accuracy: 0.5195\n",
            "Epoch 82/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.0395e-09 - accuracy: 0.5195\n",
            "Epoch 83/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.2774e-10 - accuracy: 0.5195\n",
            "Epoch 84/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.4915e-08 - accuracy: 0.5195\n",
            "Epoch 85/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.2512e-08 - accuracy: 0.5195\n",
            "Epoch 86/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 9.6844e-10 - accuracy: 0.5195\n",
            "Epoch 87/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 7.4030e-10 - accuracy: 0.5195\n",
            "Epoch 88/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.7689e-09 - accuracy: 0.5195\n",
            "Epoch 89/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.3622e-09 - accuracy: 0.5195\n",
            "Epoch 90/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.8492e-09 - accuracy: 0.5195\n",
            "Epoch 91/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.7182e-10 - accuracy: 0.5195\n",
            "Epoch 92/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.2507e-09 - accuracy: 0.5195\n",
            "Epoch 93/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.1214e-10 - accuracy: 0.5195\n",
            "Epoch 94/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.1926e-09 - accuracy: 0.5195\n",
            "Epoch 95/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 6.2873e-10 - accuracy: 0.5195\n",
            "Epoch 96/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 1.6630e-10 - accuracy: 0.5195\n",
            "Epoch 97/100\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 6.4501e-10 - accuracy: 0.5195\n",
            "Epoch 98/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 5.6483e-10 - accuracy: 0.5195\n",
            "Epoch 99/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 2.7377e-09 - accuracy: 0.5195\n",
            "Epoch 100/100\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 4.4565e-10 - accuracy: 0.5195\n",
            "precision: 1.0\n",
            "recall: 0.5183585313174947\n",
            "f1-score: 0.6827880512091039\n",
            "accuracy: 0.5183585313174947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}